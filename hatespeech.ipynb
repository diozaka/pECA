{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole notebook takes around **10 minutes** to complete on a machine with Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import statsmodels.stats.multitest as mt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm # progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCP = trigger coincidence process\n",
    "\n",
    "def trigger_coincidences(X, E, taus, delta):\n",
    "    # Compute the TCP K_{tr}^{delta,taus}(E, X) for time series 'X' and\n",
    "    # event series 'E' using the sequence of thresholds 'taus' with a\n",
    "    # time tolerance of 'delta'\n",
    "    T = min(len(X), len(E))\n",
    "    K_tr = np.zeros_like(taus, dtype=int)\n",
    "    for i, tau in enumerate(taus):\n",
    "        A = (X > tau)*1\n",
    "        K_tr[i] = len([t for t in range(T-delta) if (E[t] == 1) and np.sum(A[t:t+delta+1]) >= 1])\n",
    "    return K_tr\n",
    "\n",
    "def _fit_gev_blockmaxima(X, blocksize):\n",
    "    # Fit the parameters of the GEV distribution to the maxima of blocks\n",
    "    # of size 'blocksize' in the time series 'X'\n",
    "    T = len(X) - (len(X)%blocksize) # ignore remainder\n",
    "    Mk = np.array([X[t:t+blocksize].max() for t in range(0, T, blocksize)])\n",
    "    gev_params = ss.genextreme.fit(Mk)\n",
    "    return gev_params\n",
    "\n",
    "def tcp_params_fit(X, delta, taus):\n",
    "    # Fit the parameters of the TCP Markov model (marginal and conditional probabilities)\n",
    "    # for the time series 'X', with time tolerance 'delta' and threshold sequence 'taus'\n",
    "    gev_params = _fit_gev_blockmaxima(X, delta+1)\n",
    "    ps_marginal = np.array([1.-ss.genextreme.cdf(tau, *gev_params) for tau in taus])\n",
    "    ps_conditional = np.ones_like(taus)*np.nan\n",
    "    ps_conditional[1:] = np.array([ps_marginal[i]/ps_marginal[i-1] for i in range(1,len(taus))])\n",
    "    return ps_marginal, ps_conditional\n",
    "\n",
    "def tcp_marginal_expectation(N_E, tcp_params):\n",
    "    # Compute the marginally expected TCP, i.e., the TCP that is obtained when taking the\n",
    "    # pointwise expected values independently for each threshold\n",
    "    return tcp_params[0]*N_E\n",
    "\n",
    "def tcp_nll(K_tr, N_E, idx_start, tcp_params):\n",
    "    # Compute the negative log-likelihood (test statistic value s) for the observed TCP 'K_tr',\n",
    "    # when the event series has 'N_E' event occurrences. Use threshold at position 'idx_start'\n",
    "    # as the first threshold (to shift attention to higher quantiles, default: 0), and\n",
    "    # the TCP model parameters from 'tcp_params'\n",
    "    ps_marginal, ps_conditional  = tcp_params\n",
    "    return -(ss.binom.logpmf(K_tr[idx_start], N_E, ps_marginal[idx_start])\n",
    "       + np.sum([ss.binom.logpmf(K_tr[i], K_tr[i-1], ps_conditional[i])\n",
    "                     for i in range(idx_start+1, len(ps_marginal))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_coincidences_pval(K_tr, N_E, pi):\n",
    "    return ss.binom.pmf(K_tr, N_E, pi) + ss.binom.sf(K_tr, N_E, pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terrorist attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(\"2015-01-01\", \"2017-12-31\", freq=\"1D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download GTD from https://www.start.umd.edu/gtd/\n",
    "# We use the 2014-2017 data set\n",
    "\n",
    "#gtd = pd.read_csv(\"/path/to/gtd_14to17_0718dist.csv\", low_memory=False)\n",
    "gtd = pd.read_csv(\"/home/erik/Documents/data/globalterrorism-start/gtd_14to17_0718dist.csv\", low_memory=False)\n",
    "gtd = gtd.join(pd.to_datetime(gtd[[\"iyear\", \"imonth\", \"iday\"]].rename({\"iyear\": \"year\", \"imonth\": \"month\", \"iday\": \"day\"}, axis=\"columns\")).rename(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"date\", \"country_txt\", \"city\", \"nkill\", \"nwound\", \"gname\"]\n",
    "\n",
    "sel_islamist = ((gtd[\"gname\"] == \"Al-Qaida in the Arabian Peninsula (AQAP)\")\n",
    "                | (gtd[\"gname\"] == \"Islamic State of Iraq and the Levant (ISIL)\")\n",
    "                | (gtd[\"gname\"] == \"Jihadi-inspired extremists\")\n",
    "                | (gtd[\"gname\"] == \"Muslim extremists\"))\n",
    "sel_wena = ((gtd[\"region_txt\"] == \"Western Europe\")\n",
    "                | (gtd[\"region_txt\"] == \"North America\"))\n",
    "sel_mena = ((gtd[\"region_txt\"] == \"Middle East & North Africa\"))\n",
    "sel_min10wound = (gtd[\"nwound\"] >= 10)\n",
    "\n",
    "index = gtd.loc[\n",
    "          sel_islamist\n",
    "        & sel_wena\n",
    "        & sel_min10wound\n",
    "            ][cols].groupby(\"date\").sum().index.copy()\n",
    "eventseries = pd.Series(index=index, data=[1]*len(index), name=\"GTD\").reindex(date_range).fillna(0)\n",
    "eventseries.plot(figsize=(5,2))\n",
    "plt.show()\n",
    "\n",
    "E = eventseries.values\n",
    "\n",
    "print(\"WENA-10: %d days with events. (Several entries at the same day are viewed as a single event.)\" % eventseries.sum())\n",
    "print(\"\")\n",
    "for i, r in enumerate(gtd[sel_wena & sel_islamist & sel_min10wound].itertuples()):\n",
    "    print(i, r.date.date(), r.city, r.country_txt, r.nwound, r.nkill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_daily = pd.read_csv(\"twitter-volume.csv\", index_col=0, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in timeseries_daily.columns:\n",
    "    # preprocessing\n",
    "    data = np.log2(timeseries_daily[c].copy()+1)\n",
    "    data = data - data.rolling(window=30).mean()\n",
    "    data = data.loc[date_range]\n",
    "\n",
    "    plt.figure(figsize=(15,2))\n",
    "    plt.title(c)\n",
    "    for d in eventseries[eventseries == 1].index:\n",
    "        plt.axvline(d, color=\"red\", alpha=0.3)\n",
    "    plt.plot(data)\n",
    "    plt.xlim((date_range[0],date_range[-1]))\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4.3. Examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test whether Islamist terrorist attacks systematically trigger bursts of more than 1,000 posts per day on Twitter that contain the hashtag #stopislam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the raw time series used in this example is not stationary\n",
    "\n",
    "c = \"#stopislam\"\n",
    "data = timeseries_daily[c].loc[date_range].copy()\n",
    "thresh = 1000\n",
    "\n",
    "tcp_params = tcp_params_fit(data, delta, [thresh])\n",
    "K_tr = trigger_coincidences(data.values, E, np.array([thresh]), delta)\n",
    "pval = trigger_coincidences_pval(K_tr, E.sum(), tcp_params[0][0])\n",
    "\n",
    "plt.figure(figsize=(15,2))\n",
    "plt.title(\"%s: K=%d r=%.2f p=%.4f Delta=%d\" % (c, K_tr, K_tr/E.sum(), pval, delta))\n",
    "for d in data[data > thresh].index:\n",
    "    plt.axvline(d, color=\"blue\", alpha=0.1)\n",
    "for d in eventseries[eventseries == 1].index:\n",
    "    plt.axvline(d, color=\"red\", alpha=0.5)\n",
    "plt.plot(data)\n",
    "plt.xlim((date_range[0],date_range[-1]))\n",
    "plt.yticks([])\n",
    "plt.ylim((0,thresh))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the hypothesis that Islamist terrorist attacks systematically trigger bursts of #notinmyname usage that exceed the volume of 95% of all days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NOTE: the raw time series used in this example is not stationary\n",
    "\n",
    "c = \"#notinmyname\"\n",
    "data = timeseries_daily[c].loc[date_range].copy()\n",
    "thresh = np.percentile(data, 95)\n",
    "\n",
    "tcp_params = tcp_params_fit(data, delta, [thresh])\n",
    "K_tr = trigger_coincidences(data.values, E, np.array([thresh]), delta)\n",
    "pval = trigger_coincidences_pval(K_tr, E.sum(), tcp_params[0][0])\n",
    "\n",
    "plt.figure(figsize=(15,2))\n",
    "plt.title(\"%s: K=%d r=%.2f p=%.4f Delta=%d\" % (c, K_tr, K_tr/E.sum(), pval, delta))\n",
    "for d in data[data > thresh].index:\n",
    "    plt.axvline(d, color=\"blue\", alpha=0.1)\n",
    "for d in eventseries[eventseries == 1].index:\n",
    "    plt.axvline(d, color=\"red\", alpha=0.5)\n",
    "plt.plot(data)\n",
    "plt.xlim((date_range[0],date_range[-1]))\n",
    "plt.yticks([])\n",
    "plt.ylim((0,thresh))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.linspace(0.75, 1, 32)\n",
    "idx_start = 0\n",
    "delta = 7\n",
    "simuls = 10000\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {c: None for c in timeseries_daily.columns}\n",
    "taus = {c: None for c in timeseries_daily.columns}\n",
    "tcp_params = {c: None for c in timeseries_daily.columns}\n",
    "simul_nlls = {c: None for c in timeseries_daily.columns}\n",
    "simul_seqs = {c: None for c in timeseries_daily.columns}\n",
    "\n",
    "for c in timeseries_daily.columns:\n",
    "    data = np.log2(timeseries_daily[c].copy()+1)\n",
    "    data = data - data.rolling(window=30).mean()\n",
    "    data = data.loc[date_range]\n",
    "\n",
    "    X[c] = data.values\n",
    "    taus[c] = np.percentile(X[c],rhos*100)\n",
    "    tcp_params[c] = tcp_params_fit(X[c], delta, taus[c])\n",
    "\n",
    "    # Monte carlo simulations for statistical significance\n",
    "    simul_nlls[c] = np.zeros(simuls)\n",
    "    simul_seqs[c] = [None] * simuls\n",
    "    for s in tqdm(range(simuls), total=simuls, desc=c):\n",
    "        simul_E = np.random.permutation(E)\n",
    "        simul_seqs[c][s] = trigger_coincidences(X[c], simul_E, taus[c], delta)\n",
    "        simul_nlls[c][s] = tcp_nll(simul_seqs[c][s], simul_E.sum(), idx_start, tcp_params[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "for i, c in enumerate(timeseries_daily.columns):\n",
    "    K_tr = trigger_coincidences(X[c], E, taus[c], delta)\n",
    "    nll = tcp_nll(K_tr, E.sum(), idx_start, tcp_params[c]) \n",
    "    pval = (np.sum(simul_nlls[c] >= nll)+1)/(simuls+1)\n",
    "\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.plot(rhos, tcp_marginal_expectation(E.sum(), tcp_params[c])/E.sum())\n",
    "    plt.vlines(rhos, np.zeros_like(rhos), ss.binom.ppf(1-alpha, E.sum(), tcp_params[c][0])/E.sum(), alpha=0.2)\n",
    "    plt.plot(rhos, K_tr/E.sum())\n",
    "    plt.xlim((rhos[idx_start], rhos[-1]))\n",
    "    plt.ylim((0,1))\n",
    "    plt.title(\"%s (p%c%.4f)\" % (c,\n",
    "                    ('='  if pval > 0.0001 else '<'),\n",
    "                    (pval if pval > 0.0001 else 0.0001)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative: Multiple hypothesis testing approach with pointwise $p$-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(timeseries_daily.columns):\n",
    "    K_tr = trigger_coincidences(X[c], E, taus[c], delta)\n",
    "    pvals = np.zeros(len(rhos))\n",
    "    for m, _ in enumerate(rhos):\n",
    "        pvals[m] = trigger_coincidences_pval(K_tr[m], E.sum(), tcp_params[c][0][m])\n",
    "    print(c)\n",
    "    for method in [\"b\", \"s\", \"hs\", \"h\"]:\n",
    "        reject, pvals_adj, _, _ = mt.multipletests(pvals, alpha=alpha, method=method)\n",
    "        print(\"   \", method, \"\\t\", \"reject\" if reject.any() else \"no reject\", \"(p=%.4f)\" % pvals_adj.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
